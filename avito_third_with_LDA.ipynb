{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanaya/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "notebookstart= time.time()\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# Tf-Idf\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# LDA\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "NFOLDS = 5\n",
    "SEED = 1234\n",
    "VALID = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scikit-learn classifierのラッパークラス\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool = True):\n",
    "        if(seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOF : Out Of Fold\n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanName(text):\n",
    "    try:\n",
    "        textProc = text.lower()\n",
    "        textProc = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', textProc)\n",
    "        textProc = \" \".join(textProc.split())\n",
    "        return textProc\n",
    "    except: \n",
    "        return \"name error\"\n",
    "    \n",
    "    \n",
    "def rmse(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power((y - y0), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Load Stage\n",
      "Train shape: 1503424 Rows, 16 Columns\n",
      "Test shape: 508438 Rows, 16 Columns\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Load Stage\")\n",
    "training = pd.read_csv('/home/stanaya/.kaggle/competitions/avito-demand-prediction/train.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
    "traindex = training.index\n",
    "testing = pd.read_csv('/home/stanaya/.kaggle/competitions/avito-demand-prediction/test.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"])\n",
    "testdex = testing.index\n",
    "\n",
    "ntrain = training.shape[0]\n",
    "ntest = testing.shape[0]\n",
    "\n",
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "y = training.deal_probability.copy()\n",
    "training.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
    "print('Test shape: {} Rows, {} Columns'.format(*testing.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine Train and Test\n",
      "\n",
      "All Data shape: 2011862 Rows, 16 Columns\n"
     ]
    }
   ],
   "source": [
    "# 学習データとテストデータを統合\n",
    "print(\"Combine Train and Test\")\n",
    "df = pd.concat([training,testing],axis=0)\n",
    "del training, testing\n",
    "gc.collect()\n",
    "print('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Engineering\")\n",
    "df[\"price\"] = np.log(df[\"price\"]+0.001)\n",
    "df[\"price\"].fillna(df.price.mean(),inplace=True)\n",
    "df[\"image_top_1\"].fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b912c3c6a6ad</th>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>Свердловская область</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>5.991467</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>Private</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>1008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2dac0150717d</th>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>Самарская область</td>\n",
       "      <td>Самара</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Private</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba83aefab5dc</th>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>8.294050</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>Private</td>\n",
       "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
       "      <td>3032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02996f1dd2ea</th>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>Татарстан</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>7.696213</td>\n",
       "      <td>286</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>Company</td>\n",
       "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c90be56d2ab</th>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>Волгоградская область</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>10.596635</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>Private</td>\n",
       "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
       "      <td>2264.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id                 region              city  \\\n",
       "item_id                                                               \n",
       "b912c3c6a6ad  e00f8ff2eaf9   Свердловская область      Екатеринбург   \n",
       "2dac0150717d  39aeb48f0017      Самарская область            Самара   \n",
       "ba83aefab5dc  91e2f88dd6e3     Ростовская область    Ростов-на-Дону   \n",
       "02996f1dd2ea  bf5cccea572d              Татарстан  Набережные Челны   \n",
       "7c90be56d2ab  ef50846afc0b  Волгоградская область         Волгоград   \n",
       "\n",
       "             parent_category_name               category_name  \\\n",
       "item_id                                                         \n",
       "b912c3c6a6ad          Личные вещи  Товары для детей и игрушки   \n",
       "2dac0150717d      Для дома и дачи           Мебель и интерьер   \n",
       "ba83aefab5dc  Бытовая электроника               Аудио и видео   \n",
       "02996f1dd2ea          Личные вещи  Товары для детей и игрушки   \n",
       "7c90be56d2ab            Транспорт                  Автомобили   \n",
       "\n",
       "                                  param_1     param_2 param_3  \\\n",
       "item_id                                                         \n",
       "b912c3c6a6ad    Постельные принадлежности         NaN     NaN   \n",
       "2dac0150717d                       Другое         NaN     NaN   \n",
       "ba83aefab5dc  Видео, DVD и Blu-ray плееры         NaN     NaN   \n",
       "02996f1dd2ea         Автомобильные кресла         NaN     NaN   \n",
       "7c90be56d2ab                   С пробегом  ВАЗ (LADA)    2110   \n",
       "\n",
       "                              title  \\\n",
       "item_id                               \n",
       "b912c3c6a6ad  Кокоби(кокон для сна)   \n",
       "2dac0150717d      Стойка для Одежды   \n",
       "ba83aefab5dc         Philips bluray   \n",
       "02996f1dd2ea             Автокресло   \n",
       "7c90be56d2ab         ВАЗ 2110, 2003   \n",
       "\n",
       "                                                    description      price  \\\n",
       "item_id                                                                      \n",
       "b912c3c6a6ad  Кокон для сна малыша,пользовались меньше месяц...   5.991467   \n",
       "2dac0150717d          Стойка для одежды, под вешалки. С бутика.   8.006368   \n",
       "ba83aefab5dc  В хорошем состоянии, домашний кинотеатр с blu ...   8.294050   \n",
       "02996f1dd2ea                             Продам кресло от0-25кг   7.696213   \n",
       "7c90be56d2ab                           Все вопросы по телефону.  10.596635   \n",
       "\n",
       "              item_seq_number activation_date user_type  \\\n",
       "item_id                                                   \n",
       "b912c3c6a6ad                2      2017-03-28   Private   \n",
       "2dac0150717d               19      2017-03-26   Private   \n",
       "ba83aefab5dc                9      2017-03-20   Private   \n",
       "02996f1dd2ea              286      2017-03-25   Company   \n",
       "7c90be56d2ab                3      2017-03-16   Private   \n",
       "\n",
       "                                                          image  image_top_1  \n",
       "item_id                                                                       \n",
       "b912c3c6a6ad  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...       1008.0  \n",
       "2dac0150717d  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...        692.0  \n",
       "ba83aefab5dc  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...       3032.0  \n",
       "02996f1dd2ea  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...        796.0  \n",
       "7c90be56d2ab  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...       2264.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Create Time Variables\n"
     ]
    }
   ],
   "source": [
    "# 曜日、週の情報を追加\n",
    "print(\"\\nCreate Time Variables\")\n",
    "df[\"Weekday\"] = df['activation_date'].dt.weekday\n",
    "df[\"Weekd of Year\"] = df['activation_date'].dt.week\n",
    "df[\"Day of Month\"] = df['activation_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encode Variables\n",
      "Encoding : ['user_id', 'region', 'city', 'parent_category_name', 'category_name', 'user_type', 'image_top_1', 'param_1', 'param_2', 'param_3']\n"
     ]
    }
   ],
   "source": [
    "# Create Validation Index and Remove Dead Variables\n",
    "# training と validation のindexを抽出(item_id)\n",
    "training_index = df.loc[df.activation_date<=pd.to_datetime('2017-04-07')].index\n",
    "validation_index = df.loc[df.activation_date>=pd.to_datetime('2017-04-08')].index\n",
    "df.drop([\"activation_date\",\"image\"],axis=1,inplace=True) # imageの情報は使わない\n",
    "\n",
    "# categoricalな特徴量を抽出する\n",
    "print(\"\\nEncode Variables\")\n",
    "categorical = [\"user_id\",\"region\",\"city\",\"parent_category_name\",\"category_name\",\"user_type\",\"image_top_1\",\"param_1\",\"param_2\",\"param_3\"]\n",
    "print(\"Encoding :\",categorical)\n",
    "\n",
    "# Encoder:\n",
    "# 文字データを離散数値に変換\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in categorical:\n",
    "    df[col].fillna('Unknown')\n",
    "    df[col] = lbl.fit_transform(df[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text Features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nText Features\")\n",
    "\n",
    "# Feature Engineering \n",
    "\n",
    "# Meta Text Features\n",
    "textfeats = [\"description\", \"title\"]\n",
    "# 句読点、括弧の数を特徴量にする\n",
    "df['desc_punc'] = df['description'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "# タイトルと説明文を正規化する\n",
    "df['title'] = df['title'].apply(lambda x: cleanName(x))\n",
    "df[\"description\"]   = df[\"description\"].apply(lambda x: cleanName(x))\n",
    "\n",
    "# タイトルと説明文の全単語数とユニークな単語種類、さらにそれらの比を撮ったものを加える\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str) \n",
    "    df[cols] = df[cols].astype(str).fillna('missing') # FILL NA\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "df_text = df[[\"title\", \"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_replace_title = {',': ' ', '(':' ', ')': ' ', '.':' '}\n",
    "dic_replace_desc = {',': ' ', '(':' ', ')': ' ', '.':' ', '\\n': '', '\\r': '', '/': ''}\n",
    "\n",
    "def replaceTitleSomeCharSplit(s):\n",
    "    return list(filter(None, s.translate(str.maketrans(dic_replace_title)).split(\" \")))\n",
    "\n",
    "def replaceDescSomeCharSplit(s):\n",
    "    return list(filter(None, s.translate(str.maketrans(dic_replace_desc)).split(\" \")))\n",
    "\n",
    "\n",
    "def replaceTitleSomeChar(s):\n",
    "    return s.translate(str.maketrans(dic_replace_title))\n",
    "\n",
    "def replaceDescSomeChar(s):\n",
    "    return s.translate(str.maketrans(dic_replace_desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanaya/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/stanaya/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_text[\"title_split\"] = df_text[\"title\"].map(replaceTitleSomeChar)\n",
    "df_text[\"desc_split\"] = df_text[\"description\"].map(replaceDescSomeChar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_split = df_text[['title_split', 'desc_split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTitle = df_text_split['title_split'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011862"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpusTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##corpusTitle\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Modeling!\n"
     ]
    }
   ],
   "source": [
    "## Topic Model\n",
    "print(\"\\nTopic Modeling!\")\n",
    "NUM_TOPICS = 300\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "\n",
    " \n",
    "#vectorizer = CountVectorizer(min_df=5, max_df=0.9, \n",
    "#                            stop_words='russian', lowercase=True)\n",
    "vectorizer = CountVectorizer(\n",
    "            stop_words = russian_stop,\n",
    "            max_df=10,\n",
    "            min_df=10)\n",
    "data_title_vectorized = vectorizer.fit_transform(corpusTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961\n",
      "['033', '034', '045', '046', '051', '060', '065', '0a', '0gb', '0мес', '1003', '1005pxd', '100a', '1025c', '105l', '10600u', '10вт', '1122', '1132', '1142', '1170', '11кг', '1205', '1260', '1300w', '1314', '13mp', '1457', '145см', '1460', '14т', '1502', '150к', '1545', '1550', '15g', '15m', '15лет', '15мм', '15шт', '160x200', '1615', '1680', '1701', '1744', '1804', '180mm', '1811', '1843', '1866', '1871', '1925г', '1937г', '1964г', '1969г', '1984г', '1v', '1м3', '1п', '1х1', '1х2', '2000gb', '200d', '200м', '22дюйма', '2346', '24часа', '259', '2601', '26м', '2710', '2760', '279', '2835', '284', '286', '29см', '2usb', '2симки', '300р', '305х76', '3121', '320hdd', '32гига', '33021', '330232', '33ghz', '346', '3525', '35мм', '36v', '371', '376', '377', '3770k', '37рр', '397', '3e', '3w', '3в1и2в1разные', '3гига', '3р', '3с', '4000mah', '4010u', '4040', '41размер', '44рр', '45л', '464', '4690', '4х1', '500руб', '5045', '50г', '50руб', '5150', '520m', '53366', '5440а5', '5502', '552g', '5633', '573', '5738', '576', '588', '5920g', '5th', '5ггц', '5гр', '5д', '5кв', '5руб', '60x60', '60х27', '620m', '6230i', '6460', '65л', '675', '6квт', '7004', '700эр', '70км', '737', '75л', '7741', '789', '78a', '7950', '7b', '7g', '7т', '804', '80в', '80г', '80м', '8120', '819', '832', '833', '835', '85a', '85мм', '8850', '9005', '9100', '9200', '921', '950d', '951', '96742', 'a1010a20', 'a1778', 'a390', 'a40', 'a53s', 'a65', 'absolu', 'absolutex', 'access', 'adiddas', 'adizero', 'adp', 'adrenalin', 'adventures', 'agent', 'agris', 'ags', 'aguilera', 'aiken', 'ajc', 'aliexpress', 'alloy', 'alpex', 'aluminum', 'amplifier', 'apacer', 'apecs', 'appel', 'area', 'arista', 'armel', 'artistry', 'assasin', 'atlon', 'avenger', 'avsl', 'avto', 'axelvox', 'axton', 'azuro', 'b100', 'b14', 'b150', 'b550', 'b5722', 'barocco', 'basket', 'bean', 'beast', 'belamos', 'bergamo', 'bessini', 'besturn', 'beuchat', 'bia', 'bioaqua', 'bj', 'blank', 'blend', 'bombardier', 'bond', 'bonito', 'borderlands', 'bouncer', 'bounty', 'bourjois', 'break', 'brick', 'brilliant', 'broadway', 'brothers', 'bruins', 'bsli', 'bumbleride', 'buro', 'bv6000', 'c170', 'c2000', 'c2005', 'c210', 'c3592', 'c6503', 'c7115a', 'calibra', 'cartridge', 'carvin', 'catana', 'cb436a', 'changhong', 'channel', 'chauvet', 'chromecast', 'cicco', 'circle', 'clank', 'clasna', 'class10', 'classico', 'cmt', 'cod', 'codered', 'cont', 'cook', 'cooling', 'copco', 'coq', 'cor', 'cord', 'cordless', 'court', 'cronus', 'csi', 'cub', 'cucci', 'cult', 'cumulus', 'curls', 'cybershot', 'd2302', 'd3300', 'd686', 'd821', 'dadak', 'device', 'dgx', 'dicer', 'disel', 'disire', 'dks', 'dls', 'doffler', 'dolby', 'dolphin', 'dominator', 'dualcore', 'dv5', 'e2333', 'e445', 'e570', 'e6500', 'e6850', 'e9', 'e960', 'eachine', 'earth', 'ecm', 'econom', 'eden', 'egoist', 'eiffel', 'elena', 'elfa', 'ellesse', 'eltempo', 'engine', 'erbesi', 'ermenegildo', 'eros', 'esam', 'esc', 'ev', 'eve', 'every', 'ewt', 'ex2519', 'extron', 'f300', 'f3112', 'ferm', 'flair', 'folies', 'foodatlas', 'formydogs', 'forte', 'four', 'freeride', 'frenza', 'frozr', 'fs402', 'fs551', 'future', 'fv', 'fx45', 'g313h', 'g361h', 'g925f', 'gaiden', 'gaude', 'gc6', 'gellar', 'gf210', 'gino', 'gioseppo', 'gipfel', 'glider', 'gls', 'gn1', 'gnf', 'goliathus', 'goose', 'grass', 'greedy', 'gt620m', 'gt710m', 'gtx1070', 'guidance', 'guide', 'guilty', 'gxt', 'h200', 'h30', 'hanns', 'hanter', 'hardi', 'hcs', 'hd2', 'hd6450', 'hicold', 'hipro', 'hj', 'hoya', 'hr2440', 'hr5001c', 'hsctp', 'hubsan', 'hurricane', 'hydro', 'i9200', 'i9301i', 'ibridge', 'ieee', 'igora', 'imango', 'inblu', 'infant', 'ingenico', 'invader', 'irig', 'istana', 'ja', 'janita', 'jasper', 'jelly', 'jenga', 'jesou', 'jika', 'jt', 'juki', 'justice', 'jx', 'k50ij', 'k52', 'k6', 'kaori', 'karl', 'katarina', 'kato', 'kcas', 'ke', 'kf300', 'khan', 'kik', 'kings', 'kitano', 'kitchen', 'knit', 'kogel', 'korea', 'koss', 'l340', 'l60', 'lace', 'ladies', 'lamania', 'lange', 'lantra', 'lash', 'lassietec', 'lbp2900', 'leadtek', 'lga1151', 'libro', 'lii', 'limit', 'lisa', 'lj41', 'loco', 'lounge', 'lune', 'lungo', 'm12', 'm20', 'machines', 'magelan', 'magnifique', 'magnolia', 'manito', 'manli', 'many', 'marano', 'marlin', 'marni', 'maserati', 'massage', 'maxfighter', 'mcd', 'megir', 'michel', 'micron', 'mikatsu', 'mike', 'minerva', 'mj', 'mmw', 'molecula', 'momentus', 'monarch', 'monkey', 'monna', 'moonlight', 'mp210', 'mp230', 'musson', 'n50', 'n5050', 'n70', 'n910c', 'nakamichi', 'nan1', 'nanya', 'nas', 'nasomatto', 'naumann', 'nes', 'netbook', 'neva', 'nicer', 'nihilo', 'norman', 'novex', 'now', 'nozomi', 'nru', 'nu', 'octa', 'oled', 'oley', 'olimp', 'olt', 'olympia', 'omer', 'opi', 'optiplex', 'orbea', 'orico', 'osiris', 'ovo', 'p1005', 'p21', 'p300', 'p600', 'paint', 'pasabahce', 'pass', 'patch', 'pavillion', 'pc10600', 'pcl', 'pcs', 'pea', 'perla', 'pets', 'pex', 'phaeton', 'picture', 'pimkie', 'pireus', 'plitex', 'pluse', 'pmp7280c', 'pny', 'pola', 'pompdelux', 'powerseeker', 'praim', 'praktica', 'presea', 'printer', 'prizm', 'pro6', 'product', 'pronovias', 'protection', 'protege', 'psg', 'purmo', 'putzmeister', 'pz', 'q334', 'qbr', 'qcy', 'qualcomm', 'quality', 'racy', 'raima', 'rc50qt', 'rc530', 'rcd', 'reason', 'rec', 'religion', 'rems', 'reserverd', 'revell', 'rexant', 'rey', 'rialto', 'richard', 'rifle', 'risen', 'ritmo', 'robert', 'rocco', 'rosher', 'roy', 'ruggear', 'rumblepad', 's3650', 's530', 's70', 's800', 'sagita', 'sailor', 'sam3', 'samaung', 'samsunggt', 'sandra', 'sata2', 'sata3', 'scsi', 'sebring', 'serie', 'shaanxi', 'shape', 'shindo', 'sikom', 'silhouette', 'single', 'sirman', 'siweida', 'skarlett', 'slade', 'sms', 'snuggle', 'sofi', 'spase', 'spike', 'sportif', 'sportmax', 'st1000dm003', 'st27i', 'stainless', 'stells', 'sth', 'stop', 'straight', 'strip', 'strunal', 'sumdex', 'sunshine', 'superdrive', 'surfpad', 'swt', 'sx150', 'sz', 't111', 't370', 't60', 't84', 'talking', 'tapco', 'tascam', 'telecaster', 'theta', 'thinkcentre', 'tico', 'todey', 'tokio', 'topman', 'toprunner', 'trailmaker', 'traxter', 'trelax', 'trives', 'trolo', 'truvor', 'tuna', 'tuskan', 'tx117', 'typhoon', 'u7', 'u8950', 'unlimited', 'vacuum', 'vanille', 'veriton', 'vest', 'vetonit', 'vic', 'vicolo', 'vida', 'viessmann', 'vira', 'vitality', 'volare', 'voltage', 'voyage', 'vtx', 'w100', 'waterman', 'wayfarer', 'wd5000aakx', 'weide', 'wellington', 'widetrak', 'willy', 'winwin', 'wn727n', 'wolfdale', 'wool', 'workbook', 'wrs', 'x145', 'x220ds', 'x245', 'x600', 'x751l', 'xd', 'xedos', 'xg', 'xh', 'xline', 'z1c', 'z1compact', 'z330', 'zapp', 'zb500kg', 'zilmer', 'zipp', 'zoeva', 'zongshen', 'zota', 'а1000', 'абонентский', 'абутилон', 'аварийных', 'авббшв', 'авокадо', 'авр', 'автобетононасос', 'автобусом', 'автостекол', 'автостоянка', 'агв', 'азимут', 'азкабана', 'азов', 'аквариуме', 'акз', 'акриловую', 'активации', 'активирован', 'актрос', 'альпийской', 'альпинизма', 'алюминиевой', 'амбер', 'амели', 'ангелов', 'ангстрем', 'анциструсы', 'аппликатор', 'араукана', 'арболитовые', 'арома', 'аромалампа', 'арочный', 'асв', 'атеси', 'атрибуты', 'афанасьева', 'б1', 'баба', 'бабинный', 'бабушка', 'баллоном', 'балонь', 'бандажная', 'банке', 'баночек', 'батат', 'беговое', 'бездрожжевой', 'беззерновой', 'безынерц', 'безынерционная', 'белорусские', 'белорусское', 'бельевая', 'бенз', 'бензиновые', 'беременный', 'берёзы', 'бестраншейная', 'бетонщиков', 'биколор', 'билетов', 'бинетон', 'бирюзы', 'биссера', 'биссером', 'битлз', 'бкм', 'благоустройства', 'бланка', 'близка', 'близких', 'блинов', 'блистере', 'блондинок', 'блох', 'блюдцем', 'бог', 'богдан', 'богоматерь', 'болванки', 'болезней', 'большемерят', 'боня', 'ботильончики', 'бразер', 'браке', 'браш', 'бретелях', 'бриджами', 'британчики', 'бронзы', 'бругмансия', 'бсс', 'бубен', 'букетики', 'буклетов', 'булгаков', 'бутика', 'бэмби', 'бюсгалтер', 'вакууме', 'валковая', 'валяные', 'ванс', 'варианта', 'вейдерсы', 'велозамок', 'велопокрышки', 'вельш', 'венгерский', 'веранд', 'версачи', 'весной', 'взрослое', 'ви', 'вибратора', 'видеопроигрыватель', 'видно', 'виза', 'византия', 'вика', 'викинги', 'вильмонт', 'винилового', 'винная', 'виртуальные', 'витра', 'внеш', 'воблера', 'водичка', 'военнослужащих', 'воздуховоды', 'возможностью', 'возрост', 'возьмем', 'воланом', 'волгодонск', 'воровайки', 'воронежа', 'воротники', 'воскресенье', 'востока', 'всадник', 'всборе', 'всесезонные', 'вскрыша', 'вторичный', 'вузы', 'выжигание', 'выпускнова', 'вых', 'вышевкой', 'вышитую', 'вяз', 'вязальной', 'газоанализатор', 'газонов', 'газоны', 'газосварочное', 'галогенная', 'галогеновый', 'гамачок', 'гардеробный', 'гарнитурой', 'гастроемкость', 'гвоздика', 'гелевое', 'гельлак', 'гепард', 'гербицид', 'гетт', 'гидравлики', 'гильза', 'гипоалергенный', 'глории', 'глухарь', 'горизонтальное', 'городская', 'горшочке', 'гостиные', 'готовимся', 'готовой', 'готовых', 'граммофон', 'гранатами', 'гретта', 'грибочки', 'громкий', 'гружу', 'грузим', 'грузопассажирские', 'грядка', 'грязевая', 'гусиный', 'гусыни', 'гусыня', 'д20', 'дакота', 'далматин', 'дачник', 'двиг', 'движок', 'двойняшкам', 'двухканальный', 'двухслойный', 'двухстворчатые', 'девичья', 'девон', 'девчуля', 'декабристы', 'декоротивные', 'делл', 'деловых', 'демасони', 'демисезонн', 'демисезонных', 'демо', 'демосезонный', 'дендробена', 'дератизация', 'деревня', 'деревообработки', 'деская', 'десткий', 'детектива', 'деткие', 'джегенсы', 'джем', 'джентельмен', 'джина', 'джинц', 'джисы', 'джогеры', 'джузеппе', 'дзи', 'диалог', 'димесезонное', 'динамометрический', 'диона', 'диплом', 'диске', 'длинном', 'днища', 'долина', 'домана', 'домкраты', 'домовята', 'домофонных', 'донбасс', 'доращивание', 'доченьки', 'дпс', 'драйверов', 'драм', 'дратхаара', 'драцены', 'древесные', 'дробленый', 'ду100', 'ду20', 'дудочки', 'дымохода', 'дымчатый', 'евровагонкой', 'евроцентов', 'едовой', 'елочка', 'емкостью', 'её', 'жара', 'жвачки', 'железных', 'жеребята', 'жигули', 'жилая', 'жить', 'жк15', 'жосткий', 'журавлик', 'завертяева', 'завтрак', 'заграничные', 'заземления', 'зака', 'закладки', 'закруглёнными', 'закрутка', 'замеры', 'замечательном', 'запечатанная', 'записей', 'заполняю', 'запуска', 'запчясти', 'застежкой', 'заявлений', 'зверей', 'звуковую', 'звуковыми', 'зеленой', 'зелёного', 'зеркальными', 'зерцалия', 'зефирки', 'зимним', 'зож', 'зон', 'зоо23', 'играем', 'игрового', 'игрунок', 'игуана', 'идеи', 'иерусалима', 'изм', 'инвестиции', 'индо', 'инертные', 'инертных', 'инженерный', 'инсталляции', 'интерьерное', 'ионный', 'исполнение', 'исправна', 'истребитель', 'итальянских', 'каблуком', 'кабыла', 'кавз', 'кадров', 'кайта', 'календариков', 'каменной', 'камуфлированные', 'канцелярский', 'капель', 'капроновая', 'капюшона', 'карамелли', 'карамзин', 'кардиганом', 'каре', 'карен', 'карибского', 'каркасе', 'кармашками', 'карника', 'карпа', 'картонная', 'катаю', 'катеджей', 'кател', 'катеров', 'катка', 'катки', 'каштана', 'квадраты', 'квадроциклов', 'квинта', 'квк', 'кгхл', 'кегли', 'кемпинг', 'кенка', 'керамик', 'кери', 'керма', 'кессон', 'кинап', 'кинескоп', 'кип', 'кирпичей', 'кирпичик', 'кисточек', 'китайском', 'китайскому', 'клапаны', 'класика', 'клеем', 'клининга', 'клю', 'клёвая', 'коврика', 'кожазам', 'кожухе', 'козырьков', 'коктейля', 'колпачок', 'колумбийская', 'кольце', 'коляка', 'комбайны', 'коммерческий', 'комн', 'комо', 'компле', 'комплектующими', 'комплет', 'компонентный', 'компост', 'компресор', 'компрессоры', 'компьютерщик', 'компьютор', 'компютерный', 'комфортный', 'конвейер', 'конвертом', 'конвертор', 'конина', 'коническая', 'консервированные', 'консиллер', 'константин', 'концепт', 'копалка', 'кораллы', 'корелл', 'корзине', 'корсар', 'кортеж', 'косметологии', 'которую', 'котэ', 'кофтачка', 'кошачья', 'крабы', 'крамер', 'красивейшая', 'краситель', 'красовочки', 'крашеный', 'кре', 'кремля', 'крепкая', 'крестьянка', 'кринолин', 'кристаллов', 'кристиан', 'крольчиху', 'кросcовки', 'кроссики', 'круглого', 'кружевным', 'крупном', 'ксюша', 'кукурузный', 'кулирка', 'кулич', 'культуры', 'кунгур', 'курткп', 'кэжуал', 'лабораторная', 'лава', 'ладомир', 'лазурь', 'ламинированные', 'ландрасы', 'ландрин', 'лапочки', 'латуни', 'ледогенератор', 'ледяной', 'лежит', 'лекарство', 'лекс', 'лекций', 'леонид', 'лепестков', 'лесник', 'либхер', 'лизунец', 'лилейники', 'лили', 'лиловые', 'лима', 'лимонное', 'лисицы', 'листьями', 'литья', 'лицензии', 'личное', 'личности', 'логарифмическая', 'лпо', 'лунным', 'лучшего', 'львы', 'люверсах', 'м20', 'м39', 'магнитолы', 'майкрасофт', 'макрокольца', 'максимум', 'максискутер', 'макулатуры', 'малавийские', 'малахитовая', 'маленькому', 'мальчикп', 'малярка', 'мамару', 'мандала', 'маневренная', 'марио', 'марлин', 'материнку', 'матерь', 'матр', 'матрицей', 'махагон', 'маячки', 'мебельного', 'медалей', 'медвежий', 'медвежонка', 'медвежонком', 'медицинскую', 'мезороллер', 'мелким', 'мелом', 'меридиан', 'метабо', 'мехеленская', 'меховых', 'мешками', 'мигалками', 'микроволновые', 'микросхема', 'милиции', 'миллен', 'минвата', 'миниэкскаватор', 'мио', 'миры', 'мистика', 'мицелий', 'мишень', 'мкпп', 'млг', 'мнц', 'могилами', 'можем', 'мол', 'молодок', 'молокосос', 'молотки', 'монарх', 'моне', 'монетный', 'мониторные', 'монтажной', 'морепродукты', 'морозит', 'моторчик', 'мотоцыкл', 'мотыль', 'моэм', 'мою', 'мстители', 'му', 'мультикам', 'мультимедийные', 'мультифункциональный', 'мультфильмов', 'мусульманское', 'мышкой', 'мэ', 'мячики', 'наборов', 'навигаторов', 'надписями', 'надувное', 'надёжные', 'накладных', 'напарника', 'наполнением', 'напульсники', 'наруто', 'настенно', 'настольной', 'натурально', 'натуральными', 'научное', 'нач', 'небесные', 'небесный', 'небольшое', 'небольшую', 'недолго', 'некрасов', 'необычной', 'неоновая', 'неразлучников', 'нивелира', 'низкорамного', 'никель', 'нимфа', 'новоенизкие', 'новозеландские', 'новозеландский', 'ножик', 'ножную', 'нокию', 'нордик', 'норковое', 'нормальное', 'носил', 'ночником', 'нс10', 'няней', 'обеденные', 'облаками', 'облицовки', 'обновляющий', 'оболочке', 'объекта', 'огня', 'ограда', 'огромным', 'огурчики', 'озеленения', 'окраски', 'октябрьской', 'олег', 'оленями', 'оленёнок', 'омолаживающая', 'омоложение', 'омрон', 'оправы', 'оптика', 'оптические', 'орловской', 'освещением', 'от1', 'отбеливание', 'отделачные', 'отделочно', 'отделочный', 'открывания', 'отработанном', 'отработанные', 'отремонтируем', 'отсадник', 'оттенок', 'отъездом', 'официанта', 'оформлению', 'охранные', 'очаровательных', 'очищение', 'ошн', 'п3', 'павильона', 'павлина', 'паджеро', 'пазом', 'пакетики', 'пакетный', 'паку', 'палеты', 'пам', 'пандусом', 'панорамное', 'панцирная', 'паола', 'папу', 'паровозики', 'паром', 'парфюмерию', 'парфюмы', 'патье', 'пацан', 'педалях', 'пелинальным', 'пенетрон', 'пенсионеров', 'первомайка', 'перга', 'перевозок', 'перекачки', 'перекладина', 'перепланировки', 'переплат', 'переплетчик', 'перспективная', 'перфаратор', 'песик', 'песчанки', 'петличка', 'петуний', 'пецилия', 'пик', 'пирата', 'пиратская', 'писателей', 'пистия', 'питомец', 'пище', 'пищевых', 'пламя', 'планировка', 'платешко', 'платинум', 'платком', 'платьем', 'плаща', 'плейстейшн', 'плн', 'плоских', 'площадей', 'плюшевых', 'плюшка', 'плюшки', 'плятья', 'пнв', 'пов', 'поводки', 'погремушками', 'погрузчики', 'подарками', 'подарочки', 'подбору', 'подвеску', 'подержанный', 'подкатной', 'подпотолочная', 'подснежники', 'пойнт', 'полимерное', 'полиптерус', 'полировочная', 'полиуретановый', 'полиэтиленовый', 'полного', 'полянка', 'померанцы', 'помпонов', 'помпы', 'породная', 'поролона', 'поросенка', 'поросёнок', 'портупеи', 'посадочный', 'посещение', 'посудой', 'потребителя', 'похудания', 'православный', 'праги', 'прекрасного', 'привезем', 'привоз', 'пригород', 'придачу', 'прикуриватель', 'приманок', 'принадлежностями', 'присадочный', 'приставкой', 'приставной', 'пристенная', 'пристенные', 'приточно', 'приучена', 'прихватка', 'прихожию', 'приют', 'программированию', 'программирования', 'продвижению', 'прокола', 'промышленную', 'прописи', 'прорезиненная', 'противоклещевая', 'противоударники', 'противошумные', 'профилактики', 'процесс', 'пруды', 'прыщей', 'пудру', 'пульсометром', 'путевки', 'пуходерка', 'пушап', 'пушкинской', 'пчеловодства', 'пчёлка', 'пшенично', 'пылесосу', 'пыль', 'р134', 'рабоч', 'рада', 'радиосинхронизаторы', 'радужная', 'разводной', 'разделитель', 'разнотравие', 'разными', 'разряд', 'райский', 'раскройный', 'распиловка', 'распошонки', 'рассыпчатая', 'растишка', 'расточка', 'расходомер', 'расчески', 'рафаэлло', 'реглан', 'результата', 'резьбонарезной', 'река', 'рексы', 'ресиверов', 'реставрации', 'рефератов', 'рефлектор', 'решении', 'ригонда', 'ризограф', 'римини', 'римский', 'робу', 'рожь', 'розжига', 'роллер', 'рольставней', 'ромашек', 'ронда', 'роснефть', 'россыпью', 'рост128', 'ростер', 'ростовой', 'ростовский', 'ростовской', 'ростову', 'рот', 'ротационный', 'рохли', 'рубец', 'рубином', 'рубчинский', 'русски', 'рыбный', 'рыжей', 'рэд', 'рюмками', 'с9', 'сrockid', 'сабвуферы', 'садовую', 'сады', 'саженцев', 'сайгака', 'салатового', 'салтыков', 'самовыравнивающийся', 'самого', 'самогруза', 'самоздрав', 'самочки', 'самцов', 'сантехуслуги', 'сараев', 'саратове', 'саратовская', 'сарафон', 'сва', 'свадьбе', 'сварной', 'свен', 'сверлильная', 'свете', 'светлой', 'световых', 'светофор', 'свисток', 'свитерочки', 'связано', 'связной', 'сделаны', 'сдельный', 'семей', 'сенокосилка', 'серагем', 'серги', 'сердец', 'сердечком', 'серебристой', 'серфинга', 'серёжек', 'сестрички', 'сеттер', 'сетчатые', 'сечения', 'сибирское', 'сидней', 'силиконовых', 'силумин', 'симба', 'симпатичное', 'симс', 'синтек', 'синхронизаторы', 'синхронизации', 'синюю', 'сирени', 'ситечко', 'сифоном', 'сказочные', 'скальники', 'скалярий', 'скамьи', 'ската', 'скейта', 'скидочная', 'складку', 'сковородки', 'скорняжная', 'скос', 'скрытого', 'слепки', 'сливочник', 'словакия', 'слово', 'сломана', 'службы', 'случаев', 'смита', 'смотрите', 'снежеть', 'снизу', 'собр', 'собственность', 'сода', 'создадим', 'сололифт', 'соломка', 'солярии', 'солярис', 'сонный', 'сонька', 'сооружения', 'соплеотсос', 'соревнований', 'сортиментовоз', 'сосков', 'состава', 'софта', 'соя', 'спаниэль', 'спас', 'спасите', 'спейс', 'спилковые', 'спининги', 'сплава', 'спорам', 'спутниковую', 'спутниковые', 'срезка', 'срезы', 'сср', 'старинного', 'стартеров', 'сте', 'стеклопластик', 'стеклорез', 'стеклоткань', 'стеклянных', 'стеллажей', 'стеллажом', 'стельк', 'стерн', 'стивена', 'стикер', 'стойкий', 'столешницу', 'стопка', 'стояния', 'стриженной', 'строгая', 'стройности', 'струбцины', 'стусло', 'стёганое', 'сувениров', 'суповые', 'сургут', 'сушилки', 'схождения', 'сциндапсус', 'счета', 'сысерть', 'сэф', 'т150', 'таблетка', 'тайфун', 'талисманы', 'талон', 'талоны', 'таракан', 'тарная', 'тачскрины', 'тбилиси', 'тельфера', 'телятина', 'тематикой', 'темы', 'тениса', 'тента', 'теодор', 'теплоблоков', 'тепловую', 'термометры', 'термопленка', 'термосы', 'тески', 'тетрадей', 'техасский', 'технической', 'техпомощь', 'тиара', 'тигры', 'токарь', 'толкай', 'тональное', 'тонус', 'топа', 'торпедо', 'тракторные', 'тракторов', 'транзистор', 'транспарант', 'трап', 'треки', 'тропик', 'трубные', 'трубный', 'трубопровода', 'трубоукладчик', 'трубчатый', 'тсм', 'ттл', 'туалетов', 'тупика', 'турецкой', 'турмалиновые', 'турмалином', 'тутора', 'тюбинг', 'тюли', 'тюнером', 'тёма', 'уайт', 'уборочная', 'увлажняющая', 'угл', 'уголовным', 'ударные', 'удлиненное', 'удобном', 'удостоверения', 'удочек', 'удс', 'укачивания', 'украшением', 'улицу', 'упаковк', 'употреблении', 'урб', 'уровней', 'уровнем', 'усиления', 'усилителей', 'усн', 'успенский', 'устойчивый', 'усть', 'фа', 'фазана', 'факсимильный', 'фактурный', 'фасадных', 'фасоль', 'фи', 'фигурками', 'фигурная', 'филин', 'фильтрующий', 'фирму', 'флага', 'флажок', 'фланелевые', 'фломастеры', 'флот', 'фолз', 'формовки', 'форт', 'фотоапорат', 'фотозоны', 'фотопарат', 'фотопленка', 'фотостудии', 'фрески', 'фреш', 'фрэнсис', 'фур', 'х1', 'хайбрид', 'характером', 'харли', 'хеллоу', 'хендмейд', 'хиллс', 'хилс', 'хилфигер', 'хипп', 'хлопке', 'хлопот', 'ходилка', 'хозяйки', 'хоккею', 'хохломская', 'хпэ', 'хсн', 'хутор', 'царапины', 'цветам', 'цветков', 'цветочного', 'цельной', 'центральном', 'цеплята', 'церезит', 'церковные', 'цикл', 'цилиндровый', 'циркулярной', 'циссус', 'цитрусовые', 'чадо', 'чайного', 'чан', 'частном', 'чеканки', 'чемпиона', 'червь', 'черепахой', 'честь', 'четкий', 'четырехядерный', 'чехии', 'чехословакии', 'чикаго', 'чима', 'чинар', 'чиполлино', 'чистого', 'чистое', 'чистопородная', 'чоби', 'чуда', 'чупс', 'чёрную', 'шаблон', 'шебень', 'шезлонги', 'шейпер', 'шестеренки', 'шилак', 'шиншилу', 'шифоновые', 'шишков', 'школьникам', 'шлейфы', 'шляпку', 'шов', 'шоколадно', 'шоколадных', 'шрек', 'штаб', 'штанг', 'штерн', 'штраборез', 'штрихкодов', 'штробление', 'штукатурный', 'шуб', 'шуя', 'щедрин', 'щипчики', 'щуп', 'экономике', 'экс', 'электрогазосварщик', 'электроинструменты', 'электрокаменка', 'электромашина', 'электромобили', 'электромонтажу', 'электропастух', 'электропилу', 'электропроводка', 'электростанцию', 'электроэпиляция', 'эмалированное', 'эпсон', 'эстетика', 'эстрадная', 'эстрадные', 'этикет', 'этим', 'эффектный', 'эцв', 'юных', 'яблочко', 'ядерник', 'яицо', 'японское', 'ярочки']\n"
     ]
    }
   ],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "print(len(features))\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Topic Model\n",
    "#print(\"\\nTopic Modeling!\")\n",
    "#NUM_TOPICS = 10\n",
    "#russian_stop = set(stopwords.words('russian'))\n",
    "#def get_col(col_name): return lambda x: x[col_name]\n",
    "\n",
    " \n",
    "#vectorizer = CountVectorizer(min_df=5, max_df=0.9, \n",
    "#                            stop_words='russian', lowercase=True)\n",
    "#vectorizer = CountVectorizer(\n",
    " #           ngram_range=(1, 2),\n",
    "#            stop_words = russian_stop,\n",
    "            #max_features=7000,\n",
    "  #          preprocessor=get_col('title'))\n",
    "#data_vectorized = vectorizer.fit_transform(df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011862, 300)\n",
      "[-2.32043088e-15  1.61380479e-15 -2.36053952e-15 -1.29007543e-15\n",
      "  4.59260823e-16 -1.11670465e-15 -8.99014884e-16 -8.22566672e-16\n",
      " -3.80345118e-15 -3.46956031e-15  5.78204570e-16  6.44242775e-16\n",
      "  2.47687138e-15  6.98549285e-15  2.50594332e-15  1.98742074e-15\n",
      "  1.09357744e-14  1.34581280e-14  3.31709827e-15 -5.02353016e-15\n",
      "  4.55203860e-15 -3.30912301e-15 -9.31913588e-15  1.49831369e-15\n",
      "  3.56195818e-15 -3.12443290e-15 -3.62786488e-15 -6.61947279e-16\n",
      " -3.23621827e-15 -3.14804204e-15  2.33349375e-15 -8.90108753e-15\n",
      " -1.40243651e-15 -6.70515454e-15 -5.55242160e-15  9.05965416e-15\n",
      "  5.47826632e-15  1.77617727e-15  2.54829654e-15 -4.49752277e-16\n",
      "  9.91732543e-16  1.69310978e-15  6.93563030e-15 -5.89290608e-15\n",
      "  1.42183647e-15  3.73642984e-15  4.02194099e-15 -1.16243939e-14\n",
      " -2.66644775e-15 -8.31784318e-16 -3.98250374e-15  4.56005597e-15\n",
      " -2.82956840e-15 -4.97750963e-15 -3.20028014e-15  7.62264634e-16\n",
      " -2.22257430e-15 -6.33889038e-16 -2.18254593e-15  5.38012264e-17\n",
      "  1.60853624e-15  3.37637995e-15  3.22856398e-15 -2.92243362e-15\n",
      "  1.29650437e-15 -2.59457010e-16 -4.58727783e-15  2.90833431e-15\n",
      "  1.11875644e-15 -3.02803923e-15  3.97969988e-16  3.66264597e-15\n",
      " -2.97982013e-15 -3.87079229e-15  6.63825064e-16  1.06200445e-15\n",
      " -1.20856627e-15 -3.31048768e-15  6.29673583e-16  1.87419977e-15\n",
      " -1.46883397e-15 -1.85276546e-15 -1.57675695e-15  1.10505033e-15\n",
      "  6.84369797e-16 -6.35301518e-15 -1.38386059e-15  2.07956080e-15\n",
      "  3.35657360e-15 -1.72978459e-15  3.82341444e-15 -1.00297391e-15\n",
      " -4.33463613e-15  5.22872098e-16 -6.45066180e-16 -5.36895324e-16\n",
      " -5.84705650e-15 -3.35463905e-15 -4.37273831e-15  4.72372377e-15\n",
      "  3.47881004e-15 -1.73780552e-16 -3.20761593e-15  1.58848614e-16\n",
      " -3.01706954e-15  1.84677116e-15  4.75726956e-15 -3.45980605e-15\n",
      " -1.69064756e-15 -3.07788783e-15  1.21130327e-15 -1.38201140e-15\n",
      "  1.89259443e-15  1.20000751e-15  9.84780838e-17 -2.05857129e-15\n",
      "  2.78871925e-15  4.50750754e-15 -2.06372014e-15  1.10172746e-15\n",
      " -1.35199435e-15  1.06301875e-15 -2.54580294e-15 -3.03836683e-16\n",
      " -2.36354634e-15  2.78818896e-16 -6.31666138e-15  1.56204876e-15\n",
      "  4.03347475e-15 -6.47660690e-16  1.83968302e-15 -2.42805438e-15\n",
      " -4.68536126e-15 -2.09263941e-15 -2.63822063e-15  2.74305153e-15\n",
      " -1.18001595e-16  2.48709098e-15  3.39183460e-15  1.49877796e-16\n",
      " -4.84524785e-15  1.48613292e-15 -2.15745276e-15 -2.10036139e-15\n",
      " -1.91279771e-15 -1.36576466e-15  1.50365382e-15 -3.25895802e-16\n",
      " -2.17452757e-15  2.33041847e-15 -3.40995209e-15 -4.66761308e-16\n",
      " -5.05655813e-16  1.72945054e-15 -4.96193450e-16 -6.91945939e-16\n",
      "  1.20843890e-15  5.37245109e-15 -2.52124319e-15  2.26191317e-15\n",
      " -1.57265031e-15 -2.17077617e-15 -2.98767915e-18 -1.45720993e-15\n",
      "  1.61315765e-15 -1.41956864e-15  2.09609718e-15 -2.40031351e-15\n",
      "  1.25511590e-15 -9.46137188e-16  3.04245193e-15  1.07798959e-15\n",
      "  7.21165354e-16 -2.35917708e-16  5.70901338e-16 -3.03869528e-17\n",
      "  3.15233349e-16  6.17378544e-16 -8.30904486e-16 -1.12343522e-15\n",
      "  2.79353594e-15 -2.49810305e-16 -4.04342922e-16  2.05439589e-15\n",
      " -8.16914499e-16 -2.54026931e-15 -1.52937910e-15 -2.24013985e-15\n",
      "  9.23438237e-16 -2.02828875e-15  1.09583776e-15 -6.60796110e-17\n",
      " -3.76507664e-16 -3.06603391e-16  1.13845787e-15 -1.12742965e-16\n",
      "  6.43274092e-15  1.33320514e-15 -1.96400611e-15  5.86605237e-15\n",
      " -2.79139447e-15 -1.46343483e-15  2.15002187e-15 -1.58024591e-15\n",
      " -1.00522313e-17 -1.11999101e-16  3.82605998e-15  1.01161515e-15\n",
      " -1.13359085e-16  5.90693661e-16  8.90344703e-16 -1.13026835e-15\n",
      " -9.30378721e-17 -2.37089386e-15  4.87686544e-15  4.90291575e-15\n",
      " -6.10122367e-16  2.44273452e-15  1.82125535e-15 -2.13687173e-15\n",
      " -3.75935857e-15  8.53231941e-16  3.86760930e-16  2.16616190e-15\n",
      "  1.32542356e-15 -6.21284548e-16 -1.37957620e-16 -2.60342138e-15\n",
      " -1.09166230e-15  2.22316770e-15 -1.87747855e-15  3.04296835e-15\n",
      " -1.48662498e-15  2.37566401e-16  1.93592243e-15 -3.30566213e-15\n",
      "  2.97353558e-15 -1.11110847e-15 -9.00449307e-16 -1.12745185e-15\n",
      "  2.83948787e-15 -1.84738560e-15 -1.83784782e-15 -2.03033940e-15\n",
      "  5.05441814e-16 -1.61949005e-15 -6.49518142e-16 -1.41134950e-16\n",
      "  3.35444572e-18 -1.66112148e-15 -8.87948631e-15  2.22704682e-15\n",
      "  1.13472475e-15  5.16254064e-16  1.22723443e-15  3.18304927e-15\n",
      "  3.95323475e-15 -3.01827254e-15  3.33885403e-15 -6.70788601e-16\n",
      "  2.21853958e-15  1.30774387e-15 -4.86122733e-16 -9.47510220e-16\n",
      " -1.82549519e-15  2.38498765e-15 -6.12473692e-16  1.45647120e-15\n",
      " -6.09577980e-16  2.42850200e-16  1.77952930e-15  2.69850723e-16\n",
      " -4.12423010e-16 -2.98390660e-15 -2.08501231e-15 -1.54808450e-15\n",
      " -5.67582161e-16 -1.68025369e-15 -7.99408286e-16  9.95922076e-16\n",
      "  1.67537985e-16 -2.42038795e-15  1.27463000e-15 -2.30214089e-15\n",
      " -4.89679277e-15  2.32836935e-16 -6.19432992e-16 -1.29261431e-15\n",
      " -2.87925326e-15 -3.30289830e-15  1.69749843e-15  3.45152684e-16\n",
      "  4.47408911e-16 -5.54825020e-16  4.58490531e-15  1.04485562e-15\n",
      "  4.28823581e-16  7.47792733e-16  1.83560986e-15 -1.72418884e-16]\n"
     ]
    }
   ],
   "source": [
    "# Build a Latent Dirichlet Allocation Model\n",
    "#lda_model = LatentDirichletAllocation(n_topics=NUM_TOPICS, max_iter=10, learning_method='online')\n",
    "#lda_Z = lda_model.fit_transform(data_title_vectorized)\n",
    "#print(lda_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    " \n",
    "# Build a Non-Negative Matrix Factorization Model\n",
    "#nmf_model = NMF(n_components=NUM_TOPICS)\n",
    "#nmf_Z = nmf_model.fit_transform(data_title_vectorized)\n",
    "#print(nmf_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    " \n",
    "# Build a Latent Semantic Indexing Model\n",
    "lsi_model = TruncatedSVD(n_components=NUM_TOPICS)\n",
    "lsi_Z = lsi_model.fit_transform(data_title_vectorized)\n",
    "print(lsi_Z.shape)  # (NO_DOCUMENTS, NO_TOPICS)\n",
    " \n",
    " \n",
    "# Let's see how the first document in the corpus looks like in different topic spaces\n",
    "#print(lda_Z[0])\n",
    "#print(nmf_Z[0])\n",
    "print(lsi_Z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.353109463128523e-14\n"
     ]
    }
   ],
   "source": [
    "print(sum(lsi_Z[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
    "# ロシア語のストップワード（自然言語処理する際に一般的で役に立たない等の理由で処理対象外とする単語）の除去\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "##I added to the max_features of the description. It did not change my score much but it may be worth investigating\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=17000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('title',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words = russian_stop,\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_vect=time.time()\n",
    "\n",
    "#Fit my vectorizer on the entire dataset instead of the training rows\n",
    "#Score improved by .0001\n",
    "vectorizer.fit(df.to_dict('records'))\n",
    "\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Text Cols\n",
    "textfeats = [\"description\", \"title\"]\n",
    "df.drop(textfeats, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Dense Features with Sparse Text Bag of Words Features\n",
    "X = df.loc[traindex,:].values\n",
    "testing = df.loc[testdex,:].values\n",
    "tfvocab = df.columns.tolist()\n",
    "for shape in [X,testing]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModeling Stage\")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, random_state=1234)\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Light Gradient Boosting Regressor\")\n",
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    # 'max_depth': 15,\n",
    "    'num_leaves': 300,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.85,\n",
    "    # 'bagging_freq': 5,\n",
    "    'learning_rate': 0.019,\n",
    "    'verbose': 0\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VALID == True:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.10, random_state=1234)\n",
    "        \n",
    "    # LGBM Dataset Formatting \n",
    "    lgtrain = lgb.Dataset(X_train, y_train,\n",
    "                    feature_name=tfvocab,\n",
    "                    categorical_feature = categorical)\n",
    "    lgvalid = lgb.Dataset(X_valid, y_valid,\n",
    "                    feature_name=tfvocab,\n",
    "                    categorical_feature = categorical)\n",
    "    del X, X_train; gc.collect()\n",
    "    \n",
    "    # Go Go Go\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=n_rounds,\n",
    "        valid_sets=[lgtrain, lgvalid],\n",
    "        valid_names=['train','valid'],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    print(\"Model Evaluation Stage\")\n",
    "    print('RMSE:', np.sqrt(metrics.mean_squared_error(y_valid, lgb_clf.predict(X_valid))))\n",
    "    del X_valid ; gc.collect()\n",
    "\n",
    "else:\n",
    "    # LGBM Dataset Formatting \n",
    "    lgtrain = lgb.Dataset(X, y,\n",
    "                    feature_name=tfvocab,\n",
    "                    categorical_feature = categorical)\n",
    "    del X; gc.collect()\n",
    "    # Go Go Go\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=910,\n",
    "        verbose_eval=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Evaluation Stage\")\n",
    "lgpred = lgb_clf.predict(testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mixing lightgbm with ridge. I haven't really tested if this improves the score or not\n",
    "#blend = 0.95*lgpred + 0.05*ridge_oof_test[:,0]\n",
    "lgsub = pd.DataFrame(lgpred,columns=[\"deal_probability\"],index=testdex)\n",
    "lgsub['deal_probability'].clip(0.0, 1.0, inplace=True) # Between 0 and 1\n",
    "lgsub.to_csv(\"lgsub.csv\",index=True,header=True)\n",
    "#print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n",
    "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
